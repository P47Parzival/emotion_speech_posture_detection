{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kE40wggkrZs-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage import feature\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2WTAt1g1re4I"
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "def get_lbp_features(image):\n",
    "    lbp = feature.local_binary_pattern(image, P=24, R=8, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AJcgtBeLrmDT"
   },
   "outputs": [],
   "source": [
    "def get_hog_features(image):\n",
    "    features = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                   cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JRNrxMq6rnQs"
   },
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for img in tqdm(images, desc=\"Extracting Features\"):\n",
    "        lbp_feat = get_lbp_features(img)\n",
    "        hog_feat = get_hog_features(img)\n",
    "        combined = np.hstack([lbp_feat, hog_feat])\n",
    "        features.append(combined)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vaPHzsHYrpHa"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv(\"fer2013.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgTzyswdtG6W",
    "outputId": "6ca54a5f-d341-45d5-96e3-7b7419aaff97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 35887/35887 [00:21<00:00, 1695.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "emotion_labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy',\n",
    "                  4: 'sad', 5: 'surprise', 6: 'neutral'}\n",
    "\n",
    "tqdm.pandas()\n",
    "df['image'] = df['pixels'].progress_apply(lambda x: np.array(x.split(' '), 'float32').reshape(48, 48))\n",
    "X = np.array(df['image'].tolist())\n",
    "y = np.array(df['emotion'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TN70MoytLTw",
    "outputId": "5cedbc1a-ad1c-495c-fa81-11789f8f133f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0%|                                                                   | 0/35887 [00:00<?, ?it/s]C:\\Users\\dhruv\\anaconda3\\Lib\\site-packages\\skimage\\feature\\texture.py:360: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n",
      "Extracting Features: 100%|██████████████████████████████████████████████████████| 35887/35887 [02:08<00:00, 280.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# extracting features\n",
    "X_features = extract_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oqa3LkB1tbJt",
    "outputId": "062aaf84-a483-4851-aded-2f93fa9adc6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 926)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EeTnVgLWtfSB"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ldySrDkLtwhY"
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.0\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TrTdZUfStzXJ"
   },
   "outputs": [],
   "source": [
    "# balancing the data with SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2jOOi2Hct4tk"
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_bal)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BGUYlPKruB14"
   },
   "outputs": [],
   "source": [
    "# # Ensemble model\n",
    "# svm = SVC(kernel='linear', C=10, gamma='scale', probability=True, class_weight='balanced', random_state=42, verbose=True)\n",
    "# rf = RandomForestClassifier(n_estimators=300, class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
    "# gb = GradientBoostingClassifier(n_estimators=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GPANDx-muFX_"
   },
   "outputs": [],
   "source": [
    "# ensemble = VotingClassifier(\n",
    "#     estimators=[('svm', svm), ('rf', rf), ('gb', gb)],\n",
    "#     voting='soft'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved as 'preprocessed_data.pkl'\n",
      "Training ensemble model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Estimators:   0%|                                                                       | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Estimators:  33%|█████████████████████                                          | 1/3 [00:33<01:07, 33.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# Save preprocessed data\n",
    "joblib.dump((X_train_pca, y_train_bal, X_test_pca, y_test), 'preprocessed_data.pkl')\n",
    "print(\"Preprocessed data saved as 'preprocessed_data.pkl'\")\n",
    "\n",
    "# Ensemble model\n",
    "rf = RandomForestClassifier(n_estimators=300, class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
    "svm = SVC(kernel='linear', C=10, probability=True, class_weight='balanced', random_state=42, verbose=True)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train each model with tqdm\n",
    "estimators = [('Random Forest', rf), ('SVM', svm), ('Gradient Boosting', gb)]\n",
    "print(\"Training ensemble model...\")\n",
    "for name, estimator in tqdm(estimators, desc=\"Training Estimators\"):\n",
    "    print(f\"Training {name}...\")\n",
    "    estimator.fit(X_train_pca, y_train_bal)\n",
    "\n",
    "# Create VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[('svm', svm), ('rf', rf), ('gb', gb)], voting='soft')\n",
    "\n",
    "# Save ensemble\n",
    "joblib.dump(ensemble, 'ensemble_model.pkl')\n",
    "joblib.dump(scaler, 'scaler_ensemble_model.pkl')\n",
    "print(\"Ensemble model saved as 'ensemble_model.pkl and scaler_ensemble_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kOo_Sz1uLSS"
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "y_pred = ensemble.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nEnsemble Model Accuracy: {accuracy*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=emotion_labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqVrul4TwR3M"
   },
   "outputs": [],
   "source": [
    "# model saving\n",
    "# import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afa13fb4"
   },
   "outputs": [],
   "source": [
    "# # Save the ensemble model and the scaler to disk\n",
    "# joblib.dump(ensemble, 'ensemble_model.pkl')\n",
    "# joblib.dump(scaler, 'scalernew.pkl')\n",
    "\n",
    "# print(\"Ensemble model and scaler saved as 'ensemble_model.pkl' and 'scaler.pkl'\")\n",
    "\n",
    "# # Download the files to your local machine\n",
    "# files.download('ensemble_model.pkl')\n",
    "# files.download('scalernew.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF2LCi8Awxmv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
