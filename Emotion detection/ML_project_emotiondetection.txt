{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kE40wggkrZs-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from skimage import feature\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature extraction\n",
        "def get_lbp_features(image):\n",
        "    lbp = feature.local_binary_pattern(image, P=24, R=8, method=\"uniform\")\n",
        "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "    return hist"
      ],
      "metadata": {
        "id": "2WTAt1g1re4I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hog_features(image):\n",
        "    features = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                   cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False)\n",
        "    return features"
      ],
      "metadata": {
        "id": "AJcgtBeLrmDT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(images):\n",
        "    features = []\n",
        "    for img in tqdm(images, desc=\"Extracting Features\"):\n",
        "        lbp_feat = get_lbp_features(img)\n",
        "hog_feat = get_hog_features(img)\n",
        "        combined = np.hstack([lbp_feat, hog_feat])\n",
        "        features.append(combined)\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "JRNrxMq6rnQs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "df = pd.read_csv(\"fer2013.csv\")"
      ],
      "metadata": {
        "id": "vaPHzsHYrpHa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "emotion_labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy',\n",
        "                  4: 'sad', 5: 'surprise', 6: 'neutral'}\n",
        "\n",
        "tqdm.pandas()\n",
        "df['image'] = df['pixels'].progress_apply(lambda x: np.array(x.split(' '), 'float32').reshape(48, 48))\n",
        "X = np.array(df['image'].tolist())\n",
        "y = np.array(df['emotion'].tolist())"
      ],
      "metadata": {
        "id": "VgTzyswdtG6W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features\n",
        "X_features = extract_features(X)"
      ],
      "metadata": {
        "id": "3TN70MoytLTw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "EeTnVgLWtfSB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ldySrDkLtwhY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# balancing the data with SMOTE\n",
        "sm = SMOTE(random_state=42)\ Tobin",
        "X_train_bal, y_train_bal = sm.fit_resample(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "TrTdZUfStzXJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "pca = PCA(n_components=150, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_bal)\n",
        "X_test_pca = pca.transform(X_test_scaled)"
      ],
      "metadata": {
        "id": "2jOOi2Hct4tk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessed data to avoid re-running earlier steps\n",
        "joblib.dump((X_train_pca, y_train_bal, X_test_pca, y_test), 'preprocessed_data.pkl')\n",
        "print(\"Preprocessed data saved as 'preprocessed_data.pkl'\")"
      ],
      "metadata": {
        "id": "new_cell_save_data"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble model (without SVM)\n",
        "rf = RandomForestClassifier(n_estimators=300, class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
        "gb = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
        "\n",
        "# Train each model with tqdm\n",
        "estimators = [('Random Forest', rf), ('Gradient Boosting', gb)]\n",
        "print(\"Training ensemble model...\")\n",
        "for name, estimator in tqdm(estimators, desc=\"Training Estimators\"):\n",
        "    print(f\"Training {name}...\")\n",
        "    estimator.fit(X_train_pca, y_train_bal)\n",
        "\n",
        "# Create VotingClassifier\n",
        "ensemble = VotingClassifier(estimators=[('rf', rf), ('gb', gb)], voting='soft')\n",
        "\n",
        "# Save ensemble and scaler\n",
        "joblib.dump(ensemble, 'ensemble_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "print(\"Ensemble model and scaler saved as 'ensemble_model.pkl' and 'scaler.pkl'\")"
      ],
      "metadata": {
        "id": "new_cell_ensemble"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "y_pred = ensemble.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nEnsemble Model Accuracy: {accuracy*100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotion_labels.values()))"
      ],
      "metadata": {
        "id": "6kOo_Sz1uLSS"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}